{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# filter_eicu\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## common\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The cython extension is already loaded. To reload it, use:\n",
                        "  %reload_ext cython\n"
                    ]
                }
            ],
            "source": [
                "%load_ext cython\n",
                "import pandas as pd\n",
                "from common_eicu import *\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "TEST_MODE = False\n",
                "# TEST_MODE = True\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%cython\n",
                "import cython\n",
                "\n",
                "MINUTES_PER_DAY: cython.int = 24 * 60\n",
                "\n",
                "def minutes2days(offset: cython.int) -> cython.int:\n",
                "    return int(offset / MINUTES_PER_DAY)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## diagnosis\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 3.62 s\n",
                        "Wall time: 3.64 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "DIAGNOSIS_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_DIAGNOSIS_STRING,\n",
                "]\n",
                "\n",
                "df_diagnosis = pd.read_csv(\n",
                "    DIAGNOSIS_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=DIAGNOSIS_USE_COLS,\n",
                ")\n",
                "\n",
                "# filter diagnosis strings\n",
                "diagnosis_mask = df_diagnosis[KEY_DIAGNOSIS_STRING].map(\n",
                "    lambda diagnosis_string: (\n",
                "        SEPSIS_KEYWORD in str(diagnosis_string).lower()\n",
                "    )\n",
                ")\n",
                "df_diagnosis = df_diagnosis[diagnosis_mask].copy()\n",
                "\n",
                "if TEST_MODE:\n",
                "    DIAGNOSIS_OUTPUT_PATH = relative_path(\n",
                "        './data/sepsis_eicu_test.csv'\n",
                "    )\n",
                "else:\n",
                "    DIAGNOSIS_OUTPUT_PATH = relative_path(\n",
                "        './data/sepsis_eicu.csv.gz'\n",
                "    )\n",
                "\n",
                "df_diagnosis.to_csv(\n",
                "    DIAGNOSIS_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                "    index=False,\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## exam\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 14.5 s\n",
                        "Wall time: 14.5 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "EXAM_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_EXAM_OFFSET,\n",
                "    KEY_EXAM_NAME,\n",
                "    KEY_EXAM_RESULT,\n",
                "]\n",
                "\n",
                "df_exam = pd.read_csv(\n",
                "    EXAM_PATH,\n",
                "    usecols=EXAM_USE_COLS,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                ")\n",
                "\n",
                "# filter exam items\n",
                "exam_values = {\n",
                "    KEY_EXAM_NAME: EXAM_ITEMS,\n",
                "}\n",
                "exam_mask = df_exam.isin(exam_values).any(axis='columns')\n",
                "df_exam = df_exam[exam_mask].copy()\n",
                "\n",
                "# transform offset\n",
                "df_exam[KEY_EXAM_OFFSET] = df_exam[KEY_EXAM_OFFSET].map(minutes2days)\n",
                "\n",
                "# fix value type\n",
                "df_exam[KEY_EXAM_RESULT] = df_exam[KEY_EXAM_RESULT].astype('float')\n",
                "\n",
                "# Aggregation won't be performed on exam data frame\n",
                "# because that depends on exam name.\n",
                "# Instead, it will be done during data extraction.\n",
                "\n",
                "EXAM_OUTPUT_PATH = relative_path(\n",
                "    './data/exam_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "\n",
                "df_exam.to_csv(\n",
                "    EXAM_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## lab\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Importing data...\n",
                        "Filtering...\n",
                        "Transforming offset...\n",
                        "Computing daily means...\n",
                        "Writing to file...\n",
                        "Done.\n",
                        "CPU times: total: 2min 49s\n",
                        "Wall time: 2min 50s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "LAB_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_LAB_OFFSET,\n",
                "    KEY_LAB_NAME,\n",
                "    KEY_LAB_RESULT,\n",
                "]\n",
                "\n",
                "print('Importing data...')\n",
                "df_lab = pd.read_csv(\n",
                "    LAB_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=LAB_USE_COLS,\n",
                ")\n",
                "\n",
                "print('Filtering...')\n",
                "lab_values = {\n",
                "    KEY_LAB_NAME: LAB_VARIABLES,\n",
                "}\n",
                "lab_mask = df_lab.isin(lab_values).any(axis='columns')\n",
                "df_lab = df_lab[lab_mask].copy()\n",
                "\n",
                "print('Transforming offset...')\n",
                "df_lab[KEY_LAB_OFFSET] = df_lab[KEY_LAB_OFFSET].map(minutes2days)\n",
                "\n",
                "print('Computing daily means...')\n",
                "df_exam = df_exam \\\n",
                "    .groupby([KEY_IDENTITY, KEY_EXAM_OFFSET, KEY_EXAM_NAME]) \\\n",
                "    .mean()\n",
                "\n",
                "print('Writing to file...')\n",
                "LAB_OUTPUT_PATH = relative_path(\n",
                "    './data/lab_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "df_lab.to_csv(\n",
                "    LAB_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                "    index=False,\n",
                ")\n",
                "\n",
                "print('Done.')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## treatment\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 5.66 s\n",
                        "Wall time: 5.67 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "TREATMENT_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_TREATMENT_OFFSET,\n",
                "    KEY_TREATMENT_STRING,\n",
                "]\n",
                "\n",
                "df_treatment = pd.read_csv(\n",
                "    TREATMENT_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=TREATMENT_USE_COLS,\n",
                ")\n",
                "\n",
                "# filter treatment strings\n",
                "treatment_mask = df_treatment[KEY_TREATMENT_STRING].map(\n",
                "    lambda treatment_string: any(\n",
                "        keyword in treatment_string\n",
                "        for keyword in TREATMENT_KEYWORDS\n",
                "    )\n",
                ")\n",
                "df_treatment = df_treatment[treatment_mask].copy()\n",
                "\n",
                "# transform offset\n",
                "df_treatment[KEY_TREATMENT_OFFSET] = \\\n",
                "    df_treatment[KEY_TREATMENT_OFFSET].map(minutes2days)\n",
                "\n",
                "TREATMENT_OUTPUT_PATH = relative_path(\n",
                "    './data/treatment_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "\n",
                "df_treatment.to_csv(\n",
                "    TREATMENT_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                "    index=False,\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## aperiodic\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Importing data...\n",
                        "Transforming offsets...\n",
                        "Computing daily means...\n",
                        "Exporting data...\n",
                        "Done.\n",
                        "CPU times: total: 22.9 s\n",
                        "Wall time: 23 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "APERIODIC_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_APERIODIC_OFFSET,\n",
                "    *APERIODIC_COLUMNS,\n",
                "]\n",
                "\n",
                "print('Importing data...')\n",
                "df_aperiodic = pd.read_csv(\n",
                "    APERIODIC_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=APERIODIC_USE_COLS,\n",
                ")\n",
                "\n",
                "print('Transforming offsets...')\n",
                "df_aperiodic[KEY_APERIODIC_OFFSET] = \\\n",
                "    df_aperiodic[KEY_APERIODIC_OFFSET].map(minutes2days)\n",
                "\n",
                "print('Computing daily means...')\n",
                "df_aperiodic = df_aperiodic \\\n",
                "    .groupby([KEY_IDENTITY, KEY_APERIODIC_OFFSET]) \\\n",
                "    .mean()\n",
                "\n",
                "APERIODIC_OUTPUT_PATH = relative_path(\n",
                "    './data/aperiodic_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "\n",
                "print('Exporting data...')\n",
                "df_aperiodic.to_csv(\n",
                "    APERIODIC_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                ")\n",
                "\n",
                "print('Done.')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## periodic\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Importing data...\n",
                        "Transforming offsets...\n",
                        "Computing daily means...\n",
                        "Exporting data...\n",
                        "Done.\n",
                        "CPU times: total: 3min 5s\n",
                        "Wall time: 3min 10s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "PERIODIC_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_PERIODIC_OFFSET,\n",
                "    *PERIODIC_COLUMNS,\n",
                "]\n",
                "\n",
                "print('Importing data...')\n",
                "df_periodic = pd.read_csv(\n",
                "    PERIODIC_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=PERIODIC_USE_COLS,\n",
                ")\n",
                "\n",
                "print('Transforming offsets...')\n",
                "df_periodic[KEY_PERIODIC_OFFSET] = \\\n",
                "    df_periodic[KEY_PERIODIC_OFFSET].map(minutes2days)\n",
                "\n",
                "print('Computing daily means...')\n",
                "df_periodic = df_periodic \\\n",
                "    .groupby([KEY_IDENTITY, KEY_PERIODIC_OFFSET]) \\\n",
                "    .mean()\n",
                "\n",
                "PERIODIC_OUTPUT_PATH = relative_path(\n",
                "    './data/periodic_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "\n",
                "print('Exporting data...')\n",
                "df_periodic.to_csv(\n",
                "    PERIODIC_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                ")\n",
                "\n",
                "print('Done.')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## infusion drug\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 7.22 s\n",
                        "Wall time: 7.24 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "INFUSION_USE_COLS = [\n",
                "    KEY_IDENTITY,\n",
                "    KEY_INFUSION_OFFSET,\n",
                "    KEY_INFUSION_NAME,\n",
                "    KEY_INFUSION_AMOUNT,\n",
                "]\n",
                "\n",
                "df_infusion = pd.read_csv(\n",
                "    INFUSION_PATH,\n",
                "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
                "    usecols=INFUSION_USE_COLS,\n",
                ")\n",
                "\n",
                "\n",
                "def map_infusion_name(name):\n",
                "    if name == name:  # not NA\n",
                "        for keyword in INFUSION_KEYWORDS:\n",
                "            if keyword in name.lower():\n",
                "                return keyword\n",
                "    return pd.NA\n",
                "\n",
                "\n",
                "# map name\n",
                "df_infusion[KEY_INFUSION_NAME] = \\\n",
                "    df_infusion[KEY_INFUSION_NAME].map(map_infusion_name)\n",
                "\n",
                "# transform offset\n",
                "df_infusion[KEY_INFUSION_OFFSET] = \\\n",
                "    df_infusion[KEY_INFUSION_OFFSET].map(minutes2days)\n",
                "\n",
                "# compute daily sums\n",
                "df_infusion = df_infusion \\\n",
                "    .groupby([KEY_IDENTITY, KEY_INFUSION_OFFSET, KEY_INFUSION_NAME]) \\\n",
                "    .sum()\n",
                "\n",
                "# drop NAs\n",
                "df_infusion.dropna(inplace=True)\n",
                "\n",
                "INFUSION_OUTPUT_PATH = relative_path(\n",
                "    './data/infusion_eicu_processed'\n",
                "    + ('_test.csv' if TEST_MODE else '.csv.gz')\n",
                ")\n",
                "\n",
                "df_infusion.to_csv(\n",
                "    INFUSION_OUTPUT_PATH,\n",
                "    compression=(None if TEST_MODE else 'gzip'),\n",
                ")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "f7976576504ac6c456dadd405d7477574ca2a64265ee4724cfbc25daae5f6d94"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
