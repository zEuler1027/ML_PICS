{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract_data_eicu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common_eicu import *\n",
    "from math import isnan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROWS = 50_000\n",
    "\n",
    "COMPACT_MODE = False\n",
    "# COMPACT_MODE = True\n",
    "\n",
    "TEST_MODE = False\n",
    "# TEST_MODE = True\n",
    "\n",
    "# COMPRESS_OUTPUT = False\n",
    "COMPRESS_OUTPUT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_COMPACT\n",
    "    LAB_VARIABLES = LAB_VARIABLES_COMPACT\n",
    "    EXAM_ITEMS = EXAM_ITEMS_COMPACT\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_COMPACT\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_COMPACT\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_COMPACT\n",
    "    APERIODIC_COLUMNS = APERIODIC_COLUMNS_COMPACT\n",
    "    PERIODIC_COLUMNS = PERIODIC_COLUMNS_COMPACT\n",
    "else:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_FULL\n",
    "    LAB_VARIABLES = LAB_VARIABLES_FULL\n",
    "    EXAM_ITEMS = EXAM_ITEMS_FULL\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_FULL\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_FULL\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_FULL\n",
    "    APERIODIC_COLUMNS = APERIODIC_COLUMNS_FULL\n",
    "    PERIODIC_COLUMNS = PERIODIC_COLUMNS_FULL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the map of non-temporal data sources\n",
    "data_sources = {}\n",
    "with open(CATALOGUE_PATH, 'r') as catalogue_file:\n",
    "    catalogue = json.load(catalogue_file)\n",
    "    for column_name in NON_TEMPORAL_COLUMNS:\n",
    "        if not column_name in catalogue:\n",
    "            raise Exception(\n",
    "                f'Cannot find column \"{column_name}\" in catalogue!'\n",
    "            )\n",
    "        file_path = catalogue[column_name]\n",
    "        if file_path in data_sources:\n",
    "            data_sources[file_path].append(column_name)\n",
    "        else:\n",
    "            data_sources[file_path] = [column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect non-temporal data frames\n",
    "data_frames = []\n",
    "for input_path, column_names in data_sources.items():\n",
    "    usecols = [KEY_IDENTITY, *column_names]\n",
    "    data_frame = pd.read_csv(\n",
    "        input_path,\n",
    "        usecols=usecols,\n",
    "        index_col=KEY_IDENTITY,\n",
    "    )\n",
    "    data_frame.columns = map(\n",
    "        map_column_name,\n",
    "        data_frame.columns,\n",
    "    )\n",
    "    data_frames.append(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age(age):\n",
    "    if age != age:\n",
    "        return age\n",
    "    elif age == '> 89':\n",
    "        return 90\n",
    "    else:\n",
    "        return int(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gender(gender):\n",
    "    if gender == 'Female':\n",
    "        return 0\n",
    "    elif gender == 'Male':\n",
    "        return 1\n",
    "    else:\n",
    "        return pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200859 entries, 141168 to 3353263\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   gender  200682 non-null  object \n",
      " 1   age     200764 non-null  float64\n",
      " 2   height  196644 non-null  float64\n",
      " 3   weight  184141 non-null  float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# join non-temporal data frames\n",
    "df_non_temporal = pd.concat(\n",
    "    data_frames,\n",
    "    axis='columns',\n",
    "    join='outer',\n",
    ")\n",
    "\n",
    "# fix some columns\n",
    "df_non_temporal['age'] = df_non_temporal['age'].map(map_age)\n",
    "df_non_temporal['gender'] = df_non_temporal['gender'].map(map_gender)\n",
    "\n",
    "df_non_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200859"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identity -> { raw_col -> { 'offsets': [], 'values': []  } }\n",
    "temporal_data = {}\n",
    "\n",
    "# init indices\n",
    "for index in df_non_temporal.index:\n",
    "    temporal_data[index] = {}\n",
    "\n",
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_sepsis = pd.read_csv(\n",
    "    relative_path('./data/sepsis_eicu.csv.gz'),\n",
    "    usecols=[KEY_IDENTITY, KEY_DIAGNOSIS_STRING],\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "non_sepsis = set(temporal_data.keys())\n",
    "diagnosis_iterator = SimpleProgress(df_sepsis.index)\n",
    "for index in diagnosis_iterator:\n",
    "    identity = df_sepsis.at[index, KEY_IDENTITY]\n",
    "    non_sepsis.discard(identity)\n",
    "\n",
    "for identity in non_sepsis:\n",
    "    del temporal_data[identity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23479"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_treatment = pd.read_csv(\n",
    "    relative_path('./data/treatment_eicu_filtered.csv.gz'),\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init treatment columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        record[keyword] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect treatment info\n",
    "treatment_iterator = SimpleProgress(df_treatment.index)\n",
    "for index in treatment_iterator:\n",
    "    identity = df_treatment.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    record = temporal_data[identity]\n",
    "    raw_value = df_treatment.at[index, KEY_TREATMENT_STRING]\n",
    "    treatment_string = str(raw_value).lower()\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        if not keyword in treatment_string:\n",
    "            continue\n",
    "        offset = df_treatment.at[index, KEY_TREATMENT_OFFSET]\n",
    "        store = record[keyword]\n",
    "        store['offsets'].append(offset)\n",
    "        store['values'].append(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_exam = pd.read_csv(\n",
    "    relative_path('./data/exam_eicu_filtered.csv.gz'),\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init exam columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for item_name in EXAM_ITEMS:\n",
    "        record[item_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect exam items\n",
    "exam_iterator = SimpleProgress(df_exam.index)\n",
    "for index in exam_iterator:\n",
    "    identity = df_exam.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    item_name = df_exam.at[index, KEY_EXAM_NAME]\n",
    "    if not item_name in EXAM_ITEMS:\n",
    "        continue\n",
    "    offset = df_exam.at[index, KEY_EXAM_OFFSET]\n",
    "    value = df_exam.at[index, KEY_EXAM_RESULT]\n",
    "    record = temporal_data[identity]\n",
    "    store = record[item_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_lab = pd.read_csv(\n",
    "    relative_path('./data/lab_eicu_filtered.csv.gz'),\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init lab columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for var_name in LAB_VARIABLES:\n",
    "        record[var_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect lab variables\n",
    "lab_iterator = SimpleProgress(df_lab.index)\n",
    "for index in lab_iterator:\n",
    "    identity = df_lab.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    var_name = df_lab.at[index, KEY_LAB_NAME]\n",
    "    if not var_name in LAB_VARIABLES:\n",
    "        continue\n",
    "    offset = df_lab.at[index, KEY_LAB_OFFSET]\n",
    "    value = df_lab.at[index, KEY_LAB_RESULT]\n",
    "    record = temporal_data[identity]\n",
    "    store = record[var_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperiodic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_aperiodic = pd.read_csv(\n",
    "    relative_path('./data/aperiodic_eicu_filtered.csv.gz'),\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init aperiodic columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in APERIODIC_COLUMNS:\n",
    "        record[name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect aperiodic columns\n",
    "aperiodic_iterator = SimpleProgress(df_aperiodic.index)\n",
    "for index in aperiodic_iterator:\n",
    "    identity = df_aperiodic.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    offset = df_aperiodic.at[index, KEY_APERIODIC_OFFSET]\n",
    "    record = temporal_data[identity]\n",
    "    for name in APERIODIC_COLUMNS:\n",
    "        value = df_aperiodic.at[index, name]\n",
    "        store = record[name]\n",
    "        store['offsets'].append(offset)\n",
    "        store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_periodic = pd.read_csv(\n",
    "    relative_path('./data/periodic_eicu_filtered.csv.gz'),\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init periodic columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in PERIODIC_COLUMNS:\n",
    "        record[name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect periodic columns\n",
    "periodic_iterator = SimpleProgress(df_periodic.index)\n",
    "for index in periodic_iterator:\n",
    "    identity = df_periodic.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    offset = df_periodic.at[index, KEY_PERIODIC_OFFSET]\n",
    "    record = temporal_data[identity]\n",
    "    for name in PERIODIC_COLUMNS:\n",
    "        value = df_periodic.at[index, name]\n",
    "        store = record[name]\n",
    "        store['offsets'].append(offset)\n",
    "        store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# construct temporal data rows\n",
    "\n",
    "raw_temporal_columns = [\n",
    "    KEY_IDENTITY,\n",
    "    KEY_OFFSET,\n",
    "    *TREATMENT_KEYWORDS,\n",
    "    *EXAM_ITEMS,\n",
    "    *LAB_VARIABLES,\n",
    "    *APERIODIC_COLUMNS,\n",
    "    *PERIODIC_COLUMNS,\n",
    "]\n",
    "\n",
    "temporal_data_rows = []\n",
    "temporal_data_iterator = SimpleProgress(temporal_data.items())\n",
    "for identity, record in temporal_data_iterator:\n",
    "\n",
    "    stores = record.values()\n",
    "    all_offsets = [store['offsets'] for store in stores]\n",
    "\n",
    "    offset_begin = max(\n",
    "        min(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    offset_end = max(\n",
    "        max(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    if offset_begin < MIN_OFFSET:\n",
    "        offset_begin = MIN_OFFSET\n",
    "\n",
    "    for offset in range(offset_begin, offset_end + 1):\n",
    "        row = []\n",
    "\n",
    "        for column_name in raw_temporal_columns:\n",
    "\n",
    "            if column_name == KEY_IDENTITY:\n",
    "                row.append(identity)\n",
    "                continue\n",
    "            elif column_name == KEY_OFFSET:\n",
    "                row.append(offset)\n",
    "                continue\n",
    "\n",
    "            store = record[column_name]\n",
    "            offsets = store['offsets']\n",
    "            values = store['values']\n",
    "            count = len(offsets)\n",
    "\n",
    "            indices = list(\n",
    "                filter(\n",
    "                    lambda i: offsets[i] == offset,\n",
    "                    range(count)\n",
    "                )\n",
    "            )\n",
    "            if len(indices) == 0:\n",
    "                if len(offsets) > 0 and offsets[-1] < offset:\n",
    "                    row.append(values[-1])\n",
    "                else:\n",
    "                    row.append(pd.NA)\n",
    "            else:\n",
    "                value = mean(list(values[i] for i in indices))\n",
    "                row.append(value)\n",
    "\n",
    "        temporal_data_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134582 entries, 0 to 134581\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  134582 non-null  int64  \n",
      " 1   offset             134582 non-null  int64  \n",
      " 2   vasopressor        134582 non-null  float64\n",
      " 3   urine              45035 non-null   object \n",
      " 4   creatinine         130482 non-null  object \n",
      " 5   platelet           128924 non-null  object \n",
      " 6   inr                101202 non-null  object \n",
      " 7   pt                 98800 non-null   object \n",
      " 8   ptt                81385 non-null   object \n",
      " 9   lactate            103912 non-null  object \n",
      " 10  rdw                121697 non-null  object \n",
      " 11  bilirubin          112850 non-null  object \n",
      " 12  bicarbonate        122619 non-null  object \n",
      " 13  crp                11357 non-null   object \n",
      " 14  lymph              109655 non-null  object \n",
      " 15  albumin            116795 non-null  object \n",
      " 16  prealbumin         19599 non-null   object \n",
      " 17  wbc                129658 non-null  object \n",
      " 18  bp                 130221 non-null  object \n",
      " 19  hr                 133184 non-null  object \n",
      "dtypes: float64(1), int64(2), object(17)\n",
      "memory usage: 20.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temporal = pd.DataFrame(\n",
    "    temporal_data_rows,\n",
    "    columns=map(\n",
    "        map_column_name,\n",
    "        raw_temporal_columns,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# fill NAs in treatment columns with zeros\n",
    "for keyword in TREATMENT_KEYWORDS:\n",
    "    column_name = map_column_name(keyword)\n",
    "    df_temporal[column_name].fillna(0, inplace=True)\n",
    "\n",
    "# fill other NAs\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).ffill()\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).bfill()\n",
    "\n",
    "df_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134582 entries, 0 to 134581\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  134582 non-null  int64  \n",
      " 1   gender             134572 non-null  object \n",
      " 2   age                134582 non-null  float64\n",
      " 3   height             133864 non-null  float64\n",
      " 4   weight             130300 non-null  float64\n",
      " 5   offset             134582 non-null  int64  \n",
      " 6   vasopressor        134582 non-null  float64\n",
      " 7   urine              45035 non-null   object \n",
      " 8   creatinine         130482 non-null  object \n",
      " 9   platelet           128924 non-null  object \n",
      " 10  inr                101202 non-null  object \n",
      " 11  pt                 98800 non-null   object \n",
      " 12  ptt                81385 non-null   object \n",
      " 13  lactate            103912 non-null  object \n",
      " 14  rdw                121697 non-null  object \n",
      " 15  bilirubin          112850 non-null  object \n",
      " 16  bicarbonate        122619 non-null  object \n",
      " 17  crp                11357 non-null   object \n",
      " 18  lymph              109655 non-null  object \n",
      " 19  albumin            116795 non-null  object \n",
      " 20  prealbumin         19599 non-null   object \n",
      " 21  wbc                129658 non-null  object \n",
      " 22  bp                 130221 non-null  object \n",
      " 23  hr                 133184 non-null  object \n",
      "dtypes: float64(4), int64(2), object(18)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.merge(\n",
    "    df_non_temporal,\n",
    "    df_temporal,\n",
    "    on=KEY_IDENTITY,\n",
    ")\n",
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134582 entries, 0 to 134581\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  134582 non-null  int64  \n",
      " 1   gender             134582 non-null  float64\n",
      " 2   age                134582 non-null  float64\n",
      " 3   height             134582 non-null  float64\n",
      " 4   weight             134582 non-null  float64\n",
      " 5   offset             134582 non-null  int64  \n",
      " 6   vasopressor        134582 non-null  float64\n",
      " 7   urine              134582 non-null  float64\n",
      " 8   creatinine         134582 non-null  float64\n",
      " 9   platelet           134582 non-null  float64\n",
      " 10  inr                134582 non-null  float64\n",
      " 11  pt                 134582 non-null  float64\n",
      " 12  ptt                134582 non-null  float64\n",
      " 13  lactate            134582 non-null  float64\n",
      " 14  rdw                134582 non-null  float64\n",
      " 15  bilirubin          134582 non-null  float64\n",
      " 16  bicarbonate        134582 non-null  float64\n",
      " 17  crp                134582 non-null  float64\n",
      " 18  lymph              134582 non-null  float64\n",
      " 19  albumin            134582 non-null  float64\n",
      " 20  prealbumin         134582 non-null  float64\n",
      " 21  wbc                134582 non-null  float64\n",
      " 22  bp                 134582 non-null  float64\n",
      " 23  hr                 134582 non-null  float64\n",
      "dtypes: float64(22), int64(2)\n",
      "memory usage: 25.7 MB\n"
     ]
    }
   ],
   "source": [
    "# consider -1 as NAs\n",
    "df_output.replace(-1.0, pd.NA)\n",
    "\n",
    "# fill NAs in non-categorical columns with means\n",
    "df_output.fillna(\n",
    "    df_output.drop(columns=CATEGORICAL_COLUMNS).mean(),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# and those in categorical columns with mode values\n",
    "df_output.fillna(\n",
    "    df_output[CATEGORICAL_COLUMNS].mode().iloc[0, :],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_compact(df):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_full(df):\n",
    "\n",
    "    post_process_compact(df)\n",
    "\n",
    "    df['bmi'] = df['weight'] / (df['height'] / 100) ** 2\n",
    "    del df['weight']\n",
    "    del df['height']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    post_process_compact(df_output)\n",
    "else:\n",
    "    post_process_full(df_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134582 entries, 0 to 134581\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  134582 non-null  int64  \n",
      " 1   gender             134582 non-null  float64\n",
      " 2   age                134582 non-null  float64\n",
      " 3   offset             134582 non-null  int64  \n",
      " 4   vasopressor        134582 non-null  float64\n",
      " 5   urine              134582 non-null  float64\n",
      " 6   creatinine         134582 non-null  float64\n",
      " 7   platelet           134582 non-null  float64\n",
      " 8   inr                134582 non-null  float64\n",
      " 9   pt                 134582 non-null  float64\n",
      " 10  ptt                134582 non-null  float64\n",
      " 11  lactate            134582 non-null  float64\n",
      " 12  rdw                134582 non-null  float64\n",
      " 13  bilirubin          134582 non-null  float64\n",
      " 14  bicarbonate        134582 non-null  float64\n",
      " 15  crp                134582 non-null  float64\n",
      " 16  lymph              134582 non-null  float64\n",
      " 17  albumin            134582 non-null  float64\n",
      " 18  prealbumin         134582 non-null  float64\n",
      " 19  wbc                134582 non-null  float64\n",
      " 20  bp                 134582 non-null  float64\n",
      " 21  hr                 134582 non-null  float64\n",
      " 22  bmi                134582 non-null  float64\n",
      "dtypes: float64(21), int64(2)\n",
      "memory usage: 24.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient count: 23,479\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'patient count: {:,d}'.format(\n",
    "        len(df_output[KEY_IDENTITY].unique())\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check PICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pics(index):\n",
    "    return all(\n",
    "        indicator(df_output.at[index, col])\n",
    "        for col, indicator in PICS_CONDITIONS.items()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# Compute PICS flags:\n",
    "# `FLAG_POSITIVE` if all PICS conditions\n",
    "# are fulfilled today or yesterday;\n",
    "# `FLAG_NEGATIVE` otherwise.\n",
    "\n",
    "df_output[KEY_FLAG] = FLAG_NEGATIVE  # init\n",
    "\n",
    "last_identity = None\n",
    "last_index = None\n",
    "output_iterator = SimpleProgress(df_output.index)\n",
    "for current_index in output_iterator:\n",
    "\n",
    "    current_identity = df_output.at[current_index, KEY_IDENTITY]\n",
    "\n",
    "    if check_pics(current_index):\n",
    "        df_output.at[current_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "        if last_identity == current_identity:\n",
    "            df_output.at[last_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "\n",
    "    if (\n",
    "        last_identity != current_identity\n",
    "        and last_index != None\n",
    "        and df_output.at[last_index, KEY_FLAG] != FLAG_POSITIVE\n",
    "    ):\n",
    "        df_output.at[last_index, KEY_FLAG] = pd.NA\n",
    "\n",
    "    last_identity = current_identity\n",
    "    last_index = current_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 111511 entries, 1 to 134581\n",
      "Data columns (total 22 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   gender       111511 non-null  float64\n",
      " 1   age          111511 non-null  float64\n",
      " 2   vasopressor  111511 non-null  float64\n",
      " 3   urine        111511 non-null  float64\n",
      " 4   creatinine   111511 non-null  float64\n",
      " 5   platelet     111511 non-null  float64\n",
      " 6   inr          111511 non-null  float64\n",
      " 7   pt           111511 non-null  float64\n",
      " 8   ptt          111511 non-null  float64\n",
      " 9   lactate      111511 non-null  float64\n",
      " 10  rdw          111511 non-null  float64\n",
      " 11  bilirubin    111511 non-null  float64\n",
      " 12  bicarbonate  111511 non-null  float64\n",
      " 13  crp          111511 non-null  float64\n",
      " 14  lymph        111511 non-null  float64\n",
      " 15  albumin      111511 non-null  float64\n",
      " 16  prealbumin   111511 non-null  float64\n",
      " 17  wbc          111511 non-null  float64\n",
      " 18  bp           111511 non-null  float64\n",
      " 19  hr           111511 non-null  float64\n",
      " 20  bmi          111511 non-null  float64\n",
      " 21  flag         111511 non-null  object \n",
      "dtypes: float64(21), object(1)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove extra columns\n",
    "df_output.drop(\n",
    "    columns=[\n",
    "        KEY_IDENTITY,\n",
    "        KEY_OFFSET,\n",
    "        *CONDITION_ONLY_COLUMNS,\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# remove NA flags\n",
    "df_output.dropna(inplace=True)\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = relative_path(\n",
    "    './data/data_eicu_'\n",
    "    + ('compact' if COMPACT_MODE else 'full')\n",
    "    + ('_test' if TEST_MODE else '')\n",
    "    + '.csv'\n",
    "    + ('.gz' if COMPRESS_OUTPUT else '')\n",
    ")\n",
    "\n",
    "df_output.to_csv(\n",
    "    OUTPUT_PATH,\n",
    "    index=False,\n",
    "    compression=('gzip' if COMPRESS_OUTPUT else None),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7976576504ac6c456dadd405d7477574ca2a64265ee4724cfbc25daae5f6d94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
