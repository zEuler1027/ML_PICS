{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract_data_eicu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common_eicu import *\n",
    "from math import isnan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROWS = 50_000\n",
    "\n",
    "# COMPACT_MODE = False\n",
    "COMPACT_MODE = True\n",
    "\n",
    "TEST_MODE = False\n",
    "# TEST_MODE = True\n",
    "\n",
    "# COMPRESS_OUTPUT = False\n",
    "COMPRESS_OUTPUT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_COMPACT\n",
    "    LAB_VARIABLES = LAB_VARIABLES_COMPACT\n",
    "    EXAM_ITEMS = EXAM_ITEMS_COMPACT\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_COMPACT\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_COMPACT\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_COMPACT\n",
    "else:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_FULL\n",
    "    LAB_VARIABLES = LAB_VARIABLES_FULL\n",
    "    EXAM_ITEMS = EXAM_ITEMS_FULL\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_FULL\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_FULL\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_FULL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the map of non-temporal data sources\n",
    "data_sources = {}\n",
    "with open(CATALOGUE_PATH, 'r') as catalogue_file:\n",
    "    catalogue = json.load(catalogue_file)\n",
    "    for column_name in NON_TEMPORAL_COLUMNS:\n",
    "        if not column_name in catalogue:\n",
    "            raise Exception(\n",
    "                f'Cannot find column \"{column_name}\" in catalogue!'\n",
    "            )\n",
    "        file_path = catalogue[column_name]\n",
    "        if file_path in data_sources:\n",
    "            data_sources[file_path].append(column_name)\n",
    "        else:\n",
    "            data_sources[file_path] = [column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect non-temporal data frames\n",
    "data_frames = []\n",
    "for input_path, column_names in data_sources.items():\n",
    "    usecols = [KEY_IDENTITY, *column_names]\n",
    "    data_frame = pd.read_csv(\n",
    "        input_path,\n",
    "        usecols=usecols,\n",
    "        index_col=KEY_IDENTITY,\n",
    "    )\n",
    "    data_frame.columns = map(\n",
    "        map_column_name,\n",
    "        data_frame.columns,\n",
    "    )\n",
    "    data_frames.append(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age(age):\n",
    "    if age != age:\n",
    "        return age\n",
    "    elif age == '> 89':\n",
    "        return 90\n",
    "    else:\n",
    "        return int(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200859 entries, 141168 to 3353263\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   age     200764 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# join non-temporal data frames\n",
    "df_non_temporal = pd.concat(\n",
    "    data_frames,\n",
    "    axis='columns',\n",
    "    join='outer',\n",
    ")\n",
    "\n",
    "# fix age\n",
    "df_non_temporal['age'] = \\\n",
    "    df_non_temporal['age'].map(map_age)\n",
    "\n",
    "df_non_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200859"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identity -> { col -> { 'offsets': [], 'values': []  } }\n",
    "temporal_data = {}\n",
    "\n",
    "# init indices\n",
    "for index in df_non_temporal.index:\n",
    "    temporal_data[index] = {}\n",
    "\n",
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_sepsis = pd.read_csv(\n",
    "    relative_path('./sepsis_eicu.csv.gz'),\n",
    "    usecols=[KEY_IDENTITY, KEY_DIAGNOSIS_STRING],\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "non_sepsis = set(temporal_data.keys())\n",
    "diagnosis_iterator = SimpleProgress(df_sepsis.index)\n",
    "for index in diagnosis_iterator:\n",
    "    identity = df_sepsis.at[index, KEY_IDENTITY]\n",
    "    non_sepsis.discard(identity)\n",
    "\n",
    "for identity in non_sepsis:\n",
    "    del temporal_data[identity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23479"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_treatment = pd.read_csv(\n",
    "    relative_path('treatment_eicu_filtered.csv.gz'),\n",
    "    usecols=TREATMENT_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init treatment columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        column_name = map_column_name(keyword)\n",
    "        record[column_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect treatment info\n",
    "treatment_iterator = SimpleProgress(df_treatment.index)\n",
    "for index in treatment_iterator:\n",
    "    identity = df_treatment.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    raw_value = df_treatment.at[index, KEY_TREATMENT_STRING]\n",
    "    treatment_string = str(raw_value).lower()\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        if not keyword in treatment_string:\n",
    "            continue\n",
    "        offset = df_treatment.at[index, KEY_TREATMENT_OFFSET]\n",
    "        column_name = map_column_name(keyword)\n",
    "        store = temporal_data[identity][column_name]\n",
    "        store['offsets'].append(offset)\n",
    "        store['values'].append(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_exam = pd.read_csv(\n",
    "    relative_path('exam_eicu_filtered.csv.gz'),\n",
    "    usecols=EXAM_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init exam columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in EXAM_ITEMS:\n",
    "        column_name = map_column_name(name)\n",
    "        record[column_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect exam items\n",
    "exam_iterator = SimpleProgress(df_exam.index)\n",
    "for index in exam_iterator:\n",
    "    identity = df_exam.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    item_name = df_exam.at[index, KEY_EXAM_NAME]\n",
    "    if not item_name in EXAM_ITEMS:\n",
    "        continue\n",
    "    column_name = map_column_name(item_name)\n",
    "    offset = df_exam.at[index, KEY_EXAM_OFFSET]\n",
    "    value = df_exam.at[index, KEY_EXAM_RESULT]\n",
    "    store = temporal_data[identity][column_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_lab = pd.read_csv(\n",
    "    relative_path('lab_eicu_filtered.csv.gz'),\n",
    "    usecols=LAB_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init lab columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in LAB_VARIABLES:\n",
    "        column_name = map_column_name(name)\n",
    "        record[column_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect lab variables\n",
    "lab_iterator = SimpleProgress(df_lab.index)\n",
    "for index in lab_iterator:\n",
    "    identity = df_lab.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    var_name = df_lab.at[index, KEY_LAB_NAME]\n",
    "    if not var_name in LAB_VARIABLES:\n",
    "        continue\n",
    "    column_name = map_column_name(var_name)\n",
    "    offset = df_lab.at[index, KEY_LAB_OFFSET]\n",
    "    value = df_lab.at[index, KEY_LAB_RESULT]\n",
    "    store = temporal_data[identity][column_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# construct temporal data rows\n",
    "\n",
    "temporal_column_names = list(\n",
    "    map(map_column_name, [\n",
    "        KEY_IDENTITY,\n",
    "        KEY_OFFSET,\n",
    "        *TREATMENT_KEYWORDS,\n",
    "        *EXAM_ITEMS,\n",
    "        *LAB_VARIABLES,\n",
    "    ])\n",
    ")\n",
    "temporal_data_rows = []\n",
    "\n",
    "temporal_data_iterator = SimpleProgress(temporal_data.items())\n",
    "for identity, record in temporal_data_iterator:\n",
    "\n",
    "    stores = record.values()\n",
    "    all_offsets = [store['offsets'] for store in stores]\n",
    "\n",
    "    offset_begin = max(\n",
    "        min(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    offset_end = max(\n",
    "        max(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    if offset_begin < MIN_OFFSET:\n",
    "        offset_begin = MIN_OFFSET\n",
    "\n",
    "    for offset in range(offset_begin, offset_end + 1):\n",
    "        row = []\n",
    "\n",
    "        for column_name in temporal_column_names:\n",
    "\n",
    "            if column_name == KEY_IDENTITY:\n",
    "                row.append(identity)\n",
    "                continue\n",
    "            elif column_name == KEY_OFFSET:\n",
    "                row.append(offset)\n",
    "                continue\n",
    "\n",
    "            store = record[column_name]\n",
    "            offsets = store['offsets']\n",
    "            values = store['values']\n",
    "            count = len(offsets)\n",
    "\n",
    "            indices = list(\n",
    "                filter(\n",
    "                    lambda i: offsets[i] == offset,\n",
    "                    range(count)\n",
    "                )\n",
    "            )\n",
    "            if len(indices) == 0:\n",
    "                if len(offsets) > 0 and offsets[-1] < offset:\n",
    "                    row.append(values[-1])\n",
    "                else:\n",
    "                    row.append(pd.NA)\n",
    "            else:\n",
    "                value = mean(list(values[i] for i in indices))\n",
    "                row.append(value)\n",
    "\n",
    "        temporal_data_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131377 entries, 0 to 131376\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   patientunitstayid       131377 non-null  int64 \n",
      " 1   offset                  131377 non-null  int64 \n",
      " 2   vasopressor             42639 non-null   object\n",
      " 3   BP (systolic) Current   114932 non-null  object\n",
      " 4   BP (diastolic) Current  114925 non-null  object\n",
      " 5   hr                      111410 non-null  object\n",
      " 6   urine                   44271 non-null   object\n",
      " 7   creatinine              127359 non-null  object\n",
      " 8   platelet                125886 non-null  object\n",
      " 9   inr                     98854 non-null   object\n",
      " 10  pt                      96502 non-null   object\n",
      " 11  ptt                     79642 non-null   object\n",
      " 12  lactate                 101509 non-null  object\n",
      " 13  rdw                     118966 non-null  object\n",
      " 14  bilirubin               110110 non-null  object\n",
      " 15  bicarbonate             119717 non-null  object\n",
      " 16  crp                     11184 non-null   object\n",
      " 17  lymph                   107299 non-null  object\n",
      " 18  albumin                 113956 non-null  object\n",
      " 19  prealbumin              19231 non-null   object\n",
      " 20  wbc                     126526 non-null  object\n",
      "dtypes: int64(2), object(19)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temporal = pd.DataFrame(\n",
    "    temporal_data_rows,\n",
    "    columns=temporal_column_names,\n",
    ")\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).ffill()\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).bfill()\n",
    "\n",
    "df_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_temporal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\usr\\ECUST\\大创\\sepsis-pics\\extract_data_eicu.ipynb Cell 26\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df_non_temporal,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df_temporal,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     on\u001b[39m=\u001b[39mKEY_IDENTITY,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/usr/ECUST/%E5%A4%A7%E5%88%9B/sepsis-pics/extract_data_eicu.ipynb#Y116sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_output\u001b[39m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_temporal' is not defined"
     ]
    }
   ],
   "source": [
    "df_output = pd.merge(\n",
    "    df_non_temporal,\n",
    "    df_temporal,\n",
    "    on=KEY_IDENTITY,\n",
    ")\n",
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 131377 entries, 0 to 131376\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   patientunitstayid       131377 non-null  int64  \n",
      " 1   age                     131377 non-null  float64\n",
      " 2   offset                  131377 non-null  int64  \n",
      " 3   vasopressor             131377 non-null  float64\n",
      " 4   BP (systolic) Current   131377 non-null  float64\n",
      " 5   BP (diastolic) Current  131377 non-null  float64\n",
      " 6   hr                      131377 non-null  float64\n",
      " 7   urine                   131377 non-null  float64\n",
      " 8   creatinine              131377 non-null  float64\n",
      " 9   platelet                131377 non-null  float64\n",
      " 10  inr                     131377 non-null  float64\n",
      " 11  pt                      131377 non-null  float64\n",
      " 12  ptt                     131377 non-null  float64\n",
      " 13  lactate                 131377 non-null  float64\n",
      " 14  rdw                     131377 non-null  float64\n",
      " 15  bilirubin               131377 non-null  float64\n",
      " 16  bicarbonate             131377 non-null  float64\n",
      " 17  crp                     131377 non-null  float64\n",
      " 18  lymph                   131377 non-null  float64\n",
      " 19  albumin                 131377 non-null  float64\n",
      " 20  prealbumin              131377 non-null  float64\n",
      " 21  wbc                     131377 non-null  float64\n",
      "dtypes: float64(20), int64(2)\n",
      "memory usage: 23.1 MB\n"
     ]
    }
   ],
   "source": [
    "# consider -1 as NAs\n",
    "df_output.replace(-1.0, pd.NA)\n",
    "\n",
    "# fill NAs in non-categorical columns with means\n",
    "df_output.fillna(\n",
    "    df_output.drop(columns=CATEGORICAL_COLUMNS).mean(),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# and those in categorical columns with mode values\n",
    "df_output.fillna(\n",
    "    df_output[CATEGORICAL_COLUMNS].mode().iloc[0, :],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_compact(df):\n",
    "\n",
    "    # Mean Artery Pressure\n",
    "    df['map'] = (\n",
    "        df['BP (systolic) Current'] * 2\n",
    "        + df['BP (diastolic) Current']\n",
    "    ) / 3\n",
    "    del df['BP (systolic) Current']\n",
    "    del df['BP (diastolic) Current']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_full(df):\n",
    "\n",
    "    post_process_compact(df)\n",
    "\n",
    "    df['bmi'] = df['weight'] / (df['height'] / 100) ** 2\n",
    "    del df['weight']\n",
    "    del df['height']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    post_process_compact(df_output)\n",
    "else:\n",
    "    post_process_full(df_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 131377 entries, 0 to 131376\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  131377 non-null  int64  \n",
      " 1   age                131377 non-null  float64\n",
      " 2   offset             131377 non-null  int64  \n",
      " 3   vasopressor        131377 non-null  float64\n",
      " 4   hr                 131377 non-null  float64\n",
      " 5   urine              131377 non-null  float64\n",
      " 6   creatinine         131377 non-null  float64\n",
      " 7   platelet           131377 non-null  float64\n",
      " 8   inr                131377 non-null  float64\n",
      " 9   pt                 131377 non-null  float64\n",
      " 10  ptt                131377 non-null  float64\n",
      " 11  lactate            131377 non-null  float64\n",
      " 12  rdw                131377 non-null  float64\n",
      " 13  bilirubin          131377 non-null  float64\n",
      " 14  bicarbonate        131377 non-null  float64\n",
      " 15  crp                131377 non-null  float64\n",
      " 16  lymph              131377 non-null  float64\n",
      " 17  albumin            131377 non-null  float64\n",
      " 18  prealbumin         131377 non-null  float64\n",
      " 19  wbc                131377 non-null  float64\n",
      " 20  map                131377 non-null  float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 22.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient count: 23,479\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'patient count: {:,d}'.format(\n",
    "        len(df_output[KEY_IDENTITY].unique())\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check PICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pics(index):\n",
    "    return all(\n",
    "        indicator(df_output.at[index, col])\n",
    "        for col, indicator in PICS_CONDITIONS.items()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# Compute PICS flags:\n",
    "# `FLAG_POSITIVE` if all PICS conditions\n",
    "# are fulfilled today or yesterday;\n",
    "# `FLAG_NEGATIVE` otherwise.\n",
    "\n",
    "df_output[KEY_FLAG] = FLAG_NEGATIVE  # init\n",
    "\n",
    "last_identity = None\n",
    "last_index = None\n",
    "output_iterator = SimpleProgress(df_output.index)\n",
    "for current_index in output_iterator:\n",
    "\n",
    "    current_identity = df_output.at[current_index, KEY_IDENTITY]\n",
    "\n",
    "    if check_pics(current_index):\n",
    "        df_output.at[current_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "        if last_identity == current_identity:\n",
    "            df_output.at[last_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "\n",
    "    if (\n",
    "        last_identity != current_identity\n",
    "        and last_index != None\n",
    "        and df_output.at[last_index, KEY_FLAG] != FLAG_POSITIVE\n",
    "    ):\n",
    "        df_output.at[last_index, KEY_FLAG] = pd.NA\n",
    "\n",
    "    last_identity = current_identity\n",
    "    last_index = current_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 108296 entries, 1 to 131376\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   age          108296 non-null  float64\n",
      " 1   vasopressor  108296 non-null  float64\n",
      " 2   hr           108296 non-null  float64\n",
      " 3   urine        108296 non-null  float64\n",
      " 4   creatinine   108296 non-null  float64\n",
      " 5   platelet     108296 non-null  float64\n",
      " 6   inr          108296 non-null  float64\n",
      " 7   pt           108296 non-null  float64\n",
      " 8   ptt          108296 non-null  float64\n",
      " 9   lactate      108296 non-null  float64\n",
      " 10  rdw          108296 non-null  float64\n",
      " 11  bilirubin    108296 non-null  float64\n",
      " 12  bicarbonate  108296 non-null  float64\n",
      " 13  crp          108296 non-null  float64\n",
      " 14  lymph        108296 non-null  float64\n",
      " 15  albumin      108296 non-null  float64\n",
      " 16  prealbumin   108296 non-null  float64\n",
      " 17  wbc          108296 non-null  float64\n",
      " 18  map          108296 non-null  float64\n",
      " 19  flag         108296 non-null  object \n",
      "dtypes: float64(19), object(1)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove extra columns\n",
    "df_output.drop(\n",
    "    columns=[\n",
    "        KEY_IDENTITY,\n",
    "        KEY_OFFSET,\n",
    "        *CONDITION_ONLY_COLUMNS,\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# remove NA flags\n",
    "df_output.dropna(inplace=True)\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = relative_path(\n",
    "    'data_eicu_'\n",
    "    + ('compact' if COMPACT_MODE else 'full')\n",
    "    + ('_test' if TEST_MODE else '')\n",
    "    + '.csv'\n",
    "    + ('.gz' if COMPRESS_OUTPUT else '')\n",
    ")\n",
    "\n",
    "df_output.to_csv(\n",
    "    OUTPUT_PATH,\n",
    "    index=False,\n",
    "    compression=('gzip' if COMPRESS_OUTPUT else None),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7976576504ac6c456dadd405d7477574ca2a64265ee4724cfbc25daae5f6d94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
