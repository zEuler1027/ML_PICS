{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract_data_eicu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common_eicu import *\n",
    "from math import isnan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROWS = 50_000\n",
    "\n",
    "# COMPACT_MODE = False\n",
    "COMPACT_MODE = True\n",
    "\n",
    "TEST_MODE = False\n",
    "# TEST_MODE = True\n",
    "\n",
    "# COMPRESS_OUTPUT = False\n",
    "COMPRESS_OUTPUT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_COMPACT\n",
    "    LAB_VARIABLES = LAB_VARIABLES_COMPACT\n",
    "    EXAM_ITEMS = EXAM_ITEMS_COMPACT\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_COMPACT\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_COMPACT\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_COMPACT\n",
    "else:\n",
    "    NON_TEMPORAL_COLUMNS = NON_TEMPORAL_COLUMNS_FULL\n",
    "    LAB_VARIABLES = LAB_VARIABLES_FULL\n",
    "    EXAM_ITEMS = EXAM_ITEMS_FULL\n",
    "    TREATMENT_KEYWORDS = TREATMENT_KEYWORDS_FULL\n",
    "    CATEGORICAL_COLUMNS = CATEGORICAL_COLUMNS_FULL\n",
    "    CONDITION_ONLY_COLUMNS = CONDITION_ONLY_COLUMNS_FULL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the map of non-temporal data sources\n",
    "data_sources = {}\n",
    "with open(CATALOGUE_PATH, 'r') as catalogue_file:\n",
    "    catalogue = json.load(catalogue_file)\n",
    "    for column_name in NON_TEMPORAL_COLUMNS:\n",
    "        if not column_name in catalogue:\n",
    "            raise Exception(\n",
    "                f'Cannot find column \"{column_name}\" in catalogue!'\n",
    "            )\n",
    "        file_path = catalogue[column_name]\n",
    "        if file_path in data_sources:\n",
    "            data_sources[file_path].append(column_name)\n",
    "        else:\n",
    "            data_sources[file_path] = [column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect non-temporal data frames\n",
    "data_frames = []\n",
    "for input_path, column_names in data_sources.items():\n",
    "    usecols = [KEY_IDENTITY, *column_names]\n",
    "    data_frame = pd.read_csv(\n",
    "        input_path,\n",
    "        usecols=usecols,\n",
    "        index_col=KEY_IDENTITY,\n",
    "    )\n",
    "    data_frame.columns = map(\n",
    "        map_column_name,\n",
    "        data_frame.columns,\n",
    "    )\n",
    "    data_frames.append(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age(age):\n",
    "    if age != age:\n",
    "        return age\n",
    "    elif age == '> 89':\n",
    "        return 90\n",
    "    else:\n",
    "        return int(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200859 entries, 141168 to 3353263\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   age     200764 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# join non-temporal data frames\n",
    "df_non_temporal = pd.concat(\n",
    "    data_frames,\n",
    "    axis='columns',\n",
    "    join='outer',\n",
    ")\n",
    "\n",
    "# fix age\n",
    "df_non_temporal['age'] = \\\n",
    "    df_non_temporal['age'].map(map_age)\n",
    "\n",
    "df_non_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200859"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identity -> { col -> { 'offsets': [], 'values': []  } }\n",
    "temporal_data = {}\n",
    "\n",
    "# init indices\n",
    "for index in df_non_temporal.index:\n",
    "    temporal_data[index] = {}\n",
    "\n",
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_sepsis = pd.read_csv(\n",
    "    relative_path('./sepsis_eicu.csv.gz'),\n",
    "    usecols=[KEY_IDENTITY, KEY_DIAGNOSIS_STRING],\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "non_sepsis = set(temporal_data.keys())\n",
    "diagnosis_iterator = SimpleProgress(df_sepsis.index)\n",
    "for index in diagnosis_iterator:\n",
    "    identity = df_sepsis.at[index, KEY_IDENTITY]\n",
    "    non_sepsis.discard(identity)\n",
    "\n",
    "for identity in non_sepsis:\n",
    "    del temporal_data[identity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23479"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temporal_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_treatment = pd.read_csv(\n",
    "    relative_path('treatment_eicu_filtered.csv.gz'),\n",
    "    usecols=TREATMENT_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init treatment columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        column_name = map_column_name(keyword)\n",
    "        record[column_name] = {\n",
    "            'offsets': [MIN_OFFSET],\n",
    "            'values': [0],\n",
    "        }\n",
    "\n",
    "# collect treatment info\n",
    "treatment_iterator = SimpleProgress(df_treatment.index)\n",
    "for index in treatment_iterator:\n",
    "    identity = df_treatment.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    raw_value = df_treatment.at[index, KEY_TREATMENT_STRING]\n",
    "    treatment_string = str(raw_value).lower()\n",
    "    for keyword in TREATMENT_KEYWORDS:\n",
    "        if not keyword in treatment_string:\n",
    "            continue\n",
    "        offset = df_treatment.at[index, KEY_TREATMENT_OFFSET]\n",
    "        column_name = map_column_name(keyword)\n",
    "        store = temporal_data[identity][column_name]\n",
    "        store['offsets'].append(offset)\n",
    "        store['values'].append(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_exam = pd.read_csv(\n",
    "    relative_path('exam_eicu_filtered.csv.gz'),\n",
    "    usecols=EXAM_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init exam columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in EXAM_ITEMS:\n",
    "        column_name = map_column_name(name)\n",
    "        record[column_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect exam items\n",
    "exam_iterator = SimpleProgress(df_exam.index)\n",
    "for index in exam_iterator:\n",
    "    identity = df_exam.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    item_name = df_exam.at[index, KEY_EXAM_NAME]\n",
    "    if not item_name in EXAM_ITEMS:\n",
    "        continue\n",
    "    column_name = map_column_name(item_name)\n",
    "    offset = df_exam.at[index, KEY_EXAM_OFFSET]\n",
    "    value = df_exam.at[index, KEY_EXAM_RESULT]\n",
    "    store = temporal_data[identity][column_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "df_lab = pd.read_csv(\n",
    "    relative_path('lab_eicu_filtered.csv.gz'),\n",
    "    usecols=LAB_USE_COLS,\n",
    "    nrows=(TEST_ROWS if TEST_MODE else None),\n",
    ")\n",
    "\n",
    "# init lab columns in temporal_data\n",
    "for record in temporal_data.values():\n",
    "    for name in LAB_VARIABLES:\n",
    "        column_name = map_column_name(name)\n",
    "        record[column_name] = {\n",
    "            'offsets': [],\n",
    "            'values': [],\n",
    "        }\n",
    "\n",
    "# collect lab variables\n",
    "lab_iterator = SimpleProgress(df_lab.index)\n",
    "for index in lab_iterator:\n",
    "    identity = df_lab.at[index, KEY_IDENTITY]\n",
    "    if not identity in temporal_data:\n",
    "        continue\n",
    "    var_name = df_lab.at[index, KEY_LAB_NAME]\n",
    "    if not var_name in LAB_VARIABLES:\n",
    "        continue\n",
    "    column_name = map_column_name(var_name)\n",
    "    offset = df_lab.at[index, KEY_LAB_OFFSET]\n",
    "    value = df_lab.at[index, KEY_LAB_RESULT]\n",
    "    store = temporal_data[identity][column_name]\n",
    "    store['offsets'].append(offset)\n",
    "    store['values'].append(value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Temporal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# construct temporal data rows\n",
    "\n",
    "temporal_column_names = list(\n",
    "    map(map_column_name, [\n",
    "        KEY_IDENTITY,\n",
    "        KEY_OFFSET,\n",
    "        *TREATMENT_KEYWORDS,\n",
    "        *EXAM_ITEMS,\n",
    "        *LAB_VARIABLES,\n",
    "    ])\n",
    ")\n",
    "temporal_data_rows = []\n",
    "\n",
    "temporal_data_iterator = SimpleProgress(temporal_data.items())\n",
    "for identity, record in temporal_data_iterator:\n",
    "\n",
    "    stores = record.values()\n",
    "    all_offsets = [store['offsets'] for store in stores]\n",
    "\n",
    "    offset_begin = max(\n",
    "        min(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    offset_end = max(\n",
    "        max(offsets) if len(offsets) > 0 else MIN_OFFSET\n",
    "        for offsets in all_offsets\n",
    "    )\n",
    "    if offset_begin < MIN_OFFSET:\n",
    "        offset_begin = MIN_OFFSET\n",
    "\n",
    "    for offset in range(offset_begin, offset_end + 1):\n",
    "        row = []\n",
    "\n",
    "        for column_name in temporal_column_names:\n",
    "\n",
    "            if column_name == KEY_IDENTITY:\n",
    "                row.append(identity)\n",
    "                continue\n",
    "            elif column_name == KEY_OFFSET:\n",
    "                row.append(offset)\n",
    "                continue\n",
    "\n",
    "            store = record[column_name]\n",
    "            offsets = store['offsets']\n",
    "            values = store['values']\n",
    "            count = len(offsets)\n",
    "\n",
    "            indices = list(\n",
    "                filter(\n",
    "                    lambda i: offsets[i] == offset,\n",
    "                    range(count)\n",
    "                )\n",
    "            )\n",
    "            if len(indices) == 0:\n",
    "                if len(offsets) > 0 and offsets[-1] < offset:\n",
    "                    row.append(values[-1])\n",
    "                else:\n",
    "                    row.append(pd.NA)\n",
    "            else:\n",
    "                value = mean(list(values[i] for i in indices))\n",
    "                row.append(value)\n",
    "\n",
    "        temporal_data_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132514 entries, 0 to 132513\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   patientunitstayid       132514 non-null  int64  \n",
      " 1   offset                  132514 non-null  int64  \n",
      " 2   vasopressor             130196 non-null  float64\n",
      " 3   BP (systolic) Current   115873 non-null  float64\n",
      " 4   BP (diastolic) Current  115866 non-null  float64\n",
      " 5   hr                      112315 non-null  float64\n",
      " 6   urine                   44761 non-null   float64\n",
      " 7   creatinine              128451 non-null  float64\n",
      " 8   platelet                126975 non-null  float64\n",
      " 9   inr                     99685 non-null   float64\n",
      " 10  pt                      97318 non-null   float64\n",
      " 11  ptt                     80294 non-null   float64\n",
      " 12  lactate                 102229 non-null  float64\n",
      " 13  rdw                     119972 non-null  float64\n",
      " 14  bilirubin               111000 non-null  float64\n",
      " 15  bicarbonate             120780 non-null  float64\n",
      " 16  crp                     11305 non-null   float64\n",
      " 17  lymph                   108092 non-null  float64\n",
      " 18  albumin                 114883 non-null  float64\n",
      " 19  prealbumin              19412 non-null   float64\n",
      " 20  wbc                     127635 non-null  float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 21.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_temporal = pd.DataFrame(\n",
    "    temporal_data_rows,\n",
    "    columns=temporal_column_names,\n",
    ")\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).ffill()\n",
    "df_temporal.groupby(KEY_IDENTITY, sort=False).bfill()\n",
    "\n",
    "df_temporal.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132514 entries, 0 to 132513\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   patientunitstayid       132514 non-null  int64  \n",
      " 1   age                     132514 non-null  float64\n",
      " 2   offset                  132514 non-null  int64  \n",
      " 3   vasopressor             130196 non-null  float64\n",
      " 4   BP (systolic) Current   115873 non-null  float64\n",
      " 5   BP (diastolic) Current  115866 non-null  float64\n",
      " 6   hr                      112315 non-null  float64\n",
      " 7   urine                   44761 non-null   float64\n",
      " 8   creatinine              128451 non-null  float64\n",
      " 9   platelet                126975 non-null  float64\n",
      " 10  inr                     99685 non-null   float64\n",
      " 11  pt                      97318 non-null   float64\n",
      " 12  ptt                     80294 non-null   float64\n",
      " 13  lactate                 102229 non-null  float64\n",
      " 14  rdw                     119972 non-null  float64\n",
      " 15  bilirubin               111000 non-null  float64\n",
      " 16  bicarbonate             120780 non-null  float64\n",
      " 17  crp                     11305 non-null   float64\n",
      " 18  lymph                   108092 non-null  float64\n",
      " 19  albumin                 114883 non-null  float64\n",
      " 20  prealbumin              19412 non-null   float64\n",
      " 21  wbc                     127635 non-null  float64\n",
      "dtypes: float64(20), int64(2)\n",
      "memory usage: 23.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.merge(\n",
    "    df_non_temporal,\n",
    "    df_temporal,\n",
    "    on=KEY_IDENTITY,\n",
    ")\n",
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132514 entries, 0 to 132513\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   patientunitstayid       132514 non-null  int64  \n",
      " 1   age                     132514 non-null  float64\n",
      " 2   offset                  132514 non-null  int64  \n",
      " 3   vasopressor             132514 non-null  float64\n",
      " 4   BP (systolic) Current   132514 non-null  float64\n",
      " 5   BP (diastolic) Current  132514 non-null  float64\n",
      " 6   hr                      132514 non-null  float64\n",
      " 7   urine                   132514 non-null  float64\n",
      " 8   creatinine              132514 non-null  float64\n",
      " 9   platelet                132514 non-null  float64\n",
      " 10  inr                     132514 non-null  float64\n",
      " 11  pt                      132514 non-null  float64\n",
      " 12  ptt                     132514 non-null  float64\n",
      " 13  lactate                 132514 non-null  float64\n",
      " 14  rdw                     132514 non-null  float64\n",
      " 15  bilirubin               132514 non-null  float64\n",
      " 16  bicarbonate             132514 non-null  float64\n",
      " 17  crp                     132514 non-null  float64\n",
      " 18  lymph                   132514 non-null  float64\n",
      " 19  albumin                 132514 non-null  float64\n",
      " 20  prealbumin              132514 non-null  float64\n",
      " 21  wbc                     132514 non-null  float64\n",
      "dtypes: float64(20), int64(2)\n",
      "memory usage: 27.3 MB\n"
     ]
    }
   ],
   "source": [
    "# fill NAs in non-categorical columns with mean values\n",
    "df_output.fillna(\n",
    "    df_output.mean().drop(columns=CATEGORICAL_COLUMNS),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# and those in categorical columns with mode values\n",
    "df_output.fillna(\n",
    "    df_output[CATEGORICAL_COLUMNS].mode(),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_compact(df):\n",
    "\n",
    "    # Mean Artery Pressure\n",
    "    df['map'] = (\n",
    "        df['BP (systolic) Current'] * 2\n",
    "        + df['BP (diastolic) Current']\n",
    "    ) / 3\n",
    "    del df['BP (systolic) Current']\n",
    "    del df['BP (diastolic) Current']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_full(df):\n",
    "\n",
    "    post_process_compact(df)\n",
    "\n",
    "    df['bmi'] = df['weight'] / (df['height'] / 100) ** 2\n",
    "    del df['weight']\n",
    "    del df['height']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPACT_MODE:\n",
    "    post_process_compact(df_output)\n",
    "else:\n",
    "    post_process_full(df_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132514 entries, 0 to 132513\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   patientunitstayid  132514 non-null  int64  \n",
      " 1   age                132514 non-null  float64\n",
      " 2   offset             132514 non-null  int64  \n",
      " 3   vasopressor        132514 non-null  float64\n",
      " 4   hr                 132514 non-null  float64\n",
      " 5   urine              132514 non-null  float64\n",
      " 6   creatinine         132514 non-null  float64\n",
      " 7   platelet           132514 non-null  float64\n",
      " 8   inr                132514 non-null  float64\n",
      " 9   pt                 132514 non-null  float64\n",
      " 10  ptt                132514 non-null  float64\n",
      " 11  lactate            132514 non-null  float64\n",
      " 12  rdw                132514 non-null  float64\n",
      " 13  bilirubin          132514 non-null  float64\n",
      " 14  bicarbonate        132514 non-null  float64\n",
      " 15  crp                132514 non-null  float64\n",
      " 16  lymph              132514 non-null  float64\n",
      " 17  albumin            132514 non-null  float64\n",
      " 18  prealbumin         132514 non-null  float64\n",
      " 19  wbc                132514 non-null  float64\n",
      " 20  map                132514 non-null  float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 26.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_output.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient count: 23,479\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'patient count: {:,d}'.format(\n",
    "        len(df_output[KEY_IDENTITY].unique())\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check PICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pics(index):\n",
    "    return all(\n",
    "        indicator(df_output.at[index, col])\n",
    "        for col, indicator in PICS_CONDITIONS.items()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n"
     ]
    }
   ],
   "source": [
    "# Compute PICS flags:\n",
    "# `FLAG_POSITIVE` if all PICS conditions\n",
    "# are fulfilled today or yesterday;\n",
    "# `FLAG_NEGATIVE` otherwise.\n",
    "\n",
    "df_output[KEY_FLAG] = FLAG_NEGATIVE  # init\n",
    "\n",
    "last_identity = None\n",
    "last_index = None\n",
    "output_iterator = SimpleProgress(df_output.index)\n",
    "for current_index in output_iterator:\n",
    "\n",
    "    current_identity = df_output.at[current_index, KEY_IDENTITY]\n",
    "\n",
    "    if check_pics(current_index):\n",
    "        df_output.at[current_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "        if last_identity == current_identity:\n",
    "            df_output.at[last_index, KEY_FLAG] = FLAG_POSITIVE\n",
    "\n",
    "    if (\n",
    "        last_identity != current_identity\n",
    "        and last_index != None\n",
    "        and df_output.at[last_index, KEY_FLAG] != FLAG_POSITIVE\n",
    "    ):\n",
    "        df_output.at[last_index, KEY_FLAG] = pd.NA\n",
    "\n",
    "    last_identity = current_identity\n",
    "    last_index = current_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 109433 entries, 1 to 132513\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   age          109433 non-null  float64\n",
      " 1   offset       109433 non-null  int64  \n",
      " 2   vasopressor  109433 non-null  float64\n",
      " 3   hr           109433 non-null  float64\n",
      " 4   urine        109433 non-null  float64\n",
      " 5   creatinine   109433 non-null  float64\n",
      " 6   platelet     109433 non-null  float64\n",
      " 7   inr          109433 non-null  float64\n",
      " 8   pt           109433 non-null  float64\n",
      " 9   ptt          109433 non-null  float64\n",
      " 10  lactate      109433 non-null  float64\n",
      " 11  rdw          109433 non-null  float64\n",
      " 12  bilirubin    109433 non-null  float64\n",
      " 13  bicarbonate  109433 non-null  float64\n",
      " 14  crp          109433 non-null  float64\n",
      " 15  lymph        109433 non-null  float64\n",
      " 16  albumin      109433 non-null  float64\n",
      " 17  prealbumin   109433 non-null  float64\n",
      " 18  wbc          109433 non-null  float64\n",
      " 19  map          109433 non-null  float64\n",
      " 20  flag         109433 non-null  object \n",
      "dtypes: float64(19), int64(1), object(1)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove identity column and\n",
    "# columns that are used in conditions only\n",
    "df_output.drop(\n",
    "    columns=[\n",
    "        KEY_IDENTITY,\n",
    "        *CONDITION_ONLY_COLUMNS,\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# remove NA flags\n",
    "df_output.dropna(inplace=True)\n",
    "\n",
    "df_output.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = relative_path(\n",
    "    'data_eicu_'\n",
    "    + ('compact' if COMPACT_MODE else 'full')\n",
    "    + ('_test' if TEST_MODE else '')\n",
    "    + '.csv'\n",
    "    + ('.gz' if COMPRESS_OUTPUT else '')\n",
    ")\n",
    "\n",
    "if COMPRESS_OUTPUT:\n",
    "    df_output.to_csv(\n",
    "        OUTPUT_PATH,\n",
    "        index=False,\n",
    "        compression='gzip',\n",
    "    )\n",
    "else:\n",
    "    df_output.to_csv(\n",
    "        OUTPUT_PATH,\n",
    "        index=False,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7976576504ac6c456dadd405d7477574ca2a64265ee4724cfbc25daae5f6d94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
